{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095fcc26-78e8-4989-8a1c-dfcb6ba8e3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from sklearn import model_selection\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "from spacy.symbols import ORTH\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import luima_sbd.sbd_utils as sbd\n",
    "import os\n",
    "import fasttext\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cc0970-57f6-4ef4-814a-99251471cc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "#show all outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "def fig_prop():\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.ticklabel_format(style='plain', axis='y')\n",
    "    plt.ticklabel_format(style='plain', axis='x')\n",
    "    \n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 13})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3368c79d-9d53-4d01-b861-04ee66a7efb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5dcaea-f5bd-42cb-8a6f-b32c10187c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code from LDSI_Classifier_Workshop\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], 'd'),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8239409-23ce-4f48-814d-9c7b219859e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code from LDSI_Classifier_Workshop\n",
    "def top_tfidf_features(row, features, top_n=15):\n",
    "    ''' Get top n tfidf values in row and return them with their corresponding feature names.'''\n",
    "    topn_ids = np.argsort(row)[::-1][:top_n]\n",
    "    top_feats = [(features[i], row[i]) for i in topn_ids]\n",
    "    df = pd.DataFrame(top_feats)\n",
    "    df.columns = ['feature', 'tfidf']\n",
    "    return df\n",
    "\n",
    "\n",
    "def top_features_in_doc(Xtr, features, row_id, top_n=15):\n",
    "    ''' Top tfidf features in specific document (matrix row) '''\n",
    "    xtr_row = Xtr[row_id]\n",
    "    if type(xtr_row) is not np.ndarray:\n",
    "        xtr_row = xtr_row.toarray()\n",
    "    row = np.squeeze(xtr_row)\n",
    "    return top_tfidf_features(row, features, top_n)\n",
    "\n",
    "\n",
    "def top_mean_features(Xtr, features, grp_ids=None, min_tfidf=0.1, top_n=25):\n",
    "    ''' Return the top n features that on average are most important amongst documents in rows\n",
    "        indentified by indices in grp_ids. '''\n",
    "    if grp_ids:\n",
    "        D = Xtr[grp_ids]\n",
    "    else:\n",
    "        D = Xtr\n",
    "    if type(D) is not np.ndarray:\n",
    "        D = D.toarray()\n",
    "    D[D < min_tfidf] = 0\n",
    "    tfidf_means = np.mean(D, axis=0)\n",
    "    return top_tfidf_features(tfidf_means, features, top_n)\n",
    "\n",
    "\n",
    "def top_features_by_class(Xtr, y, features, min_tfidf=0.1, top_n=25):\n",
    "    ''' Return a list of dfs, where each df holds top_n features and their mean tfidf value\n",
    "        calculated across documents with the same class label. '''\n",
    "    dfs = {}\n",
    "    labels = np.unique(y)\n",
    "    for label in labels:\n",
    "        ids = np.where(y==label)\n",
    "        feats_df = top_mean_features(Xtr, features, ids, min_tfidf=min_tfidf, top_n=top_n)\n",
    "        feats_df.label = label\n",
    "        dfs[label] = feats_df\n",
    "    return dfs\n",
    "\n",
    "\n",
    "def span_top_tfidf(spans_txt, spans_tfidf, features, index):\n",
    "    print('span text:\\n'+spans_txt[index]+'\\n')\n",
    "    print(top_features_in_doc(spans_tfidf, features, index))\n",
    "    \n",
    "corpus_fpath = './ldsi_bva_sentence_corpus_v1.json'\n",
    "data = json.load(open(corpus_fpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d02942-63ca-4de2-bfe4-133d91ca18ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the files\n",
    "affirmed = open(\"./affirmed_ids.txt\", \"r\").read().split('\\n')\n",
    "denied = open(\"./denied_ids.txt\", \"r\").read().split('\\n')\n",
    "remanded = open(\"./remanded_ids.txt\", \"r\").read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06055fa8-c11b-4789-9820-005f761c8151",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code from LDSI_Classifier_Workshop\n",
    "annotations = data['annotations']\n",
    "documents_by_id = {d['_id']: d for d in data['documents']}\n",
    "types_by_id = {t['_id']: t for t in data['types']}\n",
    "type_ids_by_name = {t['name']: t['_id'] for t in data['types']}\n",
    "type_names_by_id = {t['_id']: t['name'] for t in data['types']}\n",
    "doc_id_by_name = {d['name']: d['_id'] for d in data['documents']}\n",
    "doc_name_by_id = {d['_id']: d['name'] for d in data['documents']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8df514-9af1-490e-a4a6-562cb42cd1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all sentences assuming every annotation is a sentence\n",
    "def make_span_data(documents_by_id, types_by_id, annotations):\n",
    "    span_data = []\n",
    "    for a in annotations:\n",
    "        start = a['start']\n",
    "        end = a['end']\n",
    "        document_txt = documents_by_id[a['document']]['plainText']\n",
    "        doc_name = documents_by_id[a['document']]['name']\n",
    "        if(doc_name in affirmed):\n",
    "            dec_label = \"affirmed\"\n",
    "        elif(doc_name in denied):\n",
    "            dec_label = \"denied\"\n",
    "        elif(doc_name in remanded):\n",
    "            dec_label = \"remanded\"\n",
    "        atype = a['type']\n",
    "        sd = {'txt': document_txt[start:end],\n",
    "              'document': a['document'],\n",
    "              'name': doc_name,\n",
    "              'decision': dec_label,\n",
    "              'type': types_by_id[atype]['name'],\n",
    "              'start': a['start'],\n",
    "              'start_normalized': a['start'] / len(document_txt),\n",
    "              'end': a['end']}\n",
    "        span_data.append(sd)\n",
    "    return span_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8a72e0-3cb0-4220-90a6-040597720267",
   "metadata": {},
   "outputs": [],
   "source": [
    "spans = make_span_data(documents_by_id, types_by_id, annotations)\n",
    "span_labels = [s['type'] for s in spans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24967028-4366-4e9d-9286-404fdec84f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "span_decisions = [s['decision'] for s in spans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f1f1a0-a959-42f7-9a67-1ef717bed3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "affirmed_ids = random.sample(affirmed, 6)\n",
    "affirmed_ids_test = affirmed_ids[0:3]\n",
    "affirmed_ids_dev = affirmed_ids[3:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebf9750-754e-4e1d-9a08-f11fec620343",
   "metadata": {},
   "outputs": [],
   "source": [
    "denied_ids = random.sample(denied, 6)\n",
    "denied_ids_test = denied_ids[0:3]\n",
    "denied_ids_dev = denied_ids[3:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13931934-09aa-49cc-9643-5a4e469ba67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "remanded_ids = random.sample(remanded, 6)\n",
    "remanded_ids_test = remanded_ids[0:3]\n",
    "remanded_ids_dev = remanded_ids[3:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f22e9b-9023-425d-b2f1-4095f212983d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids_all = affirmed_ids_test+denied_ids_test+remanded_ids_test\n",
    "dev_ids_all = affirmed_ids_dev+denied_ids_dev+remanded_ids_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c1aa00-0cb5-4feb-b85d-ac34bd0584ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_spans_new = []\n",
    "test_spans_new = []\n",
    "train_spans_new = []\n",
    "for s in spans:\n",
    "    if s['name'] in test_ids_all:\n",
    "        test_spans_new.append(s)\n",
    "    elif s['name'] in dev_ids_all:\n",
    "        dev_spans_new.append(s)\n",
    "    else:\n",
    "        train_spans_new.append(s)\n",
    "        \n",
    "df_train_spans = pd.DataFrame(train_spans_new)\n",
    "df_dev_spans = pd.DataFrame(dev_spans_new)\n",
    "df_test_spans = pd.DataFrame(test_spans_new)\n",
    "\n",
    "train_doc_list = df_train_spans['document'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f82a20a-ec0b-44de-9a36-1d889d15511d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Corpus\n",
    "train_spans_txt = [s['txt'] for s in train_spans_new]\n",
    "dev_spans_txt = [s['txt'] for s in dev_spans_new]\n",
    "test_spans_txt = [s['txt'] for s in test_spans_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61723b83-b694-49e5-a8d5-40ee9d34e507",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae740d26-ed2b-4f94-b78d-b6156f354bfe",
   "metadata": {},
   "source": [
    "### Sentence Segmenter on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13f0c95-caa2-40d0-9045-eac952c557e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_total = 0\n",
    "fp_total = 0\n",
    "fn_total = 0\n",
    "#sent_total = 0\n",
    "\n",
    "score_list = [] \n",
    "\n",
    "for index in range(len(train_doc_list)):\n",
    "    test_doc = []\n",
    "    for s in train_spans_new:\n",
    "        if(s['document']==train_doc_list[index]):\n",
    "            test_doc.append(s)\n",
    "   \n",
    "    document_txt = documents_by_id[train_doc_list[index]]['plainText']\n",
    "    doc = nlp(document_txt)\n",
    "    #sent_total += len(list(doc.sents))\n",
    "    \n",
    "    assert doc.has_annotation(\"SENT_START\")\n",
    "    \n",
    "    test_doc = sorted(test_doc, key=lambda k: k['start'])\n",
    "    \n",
    "    tp = 0\n",
    "    fp = 0\n",
    "\n",
    "    for i in range(len(test_doc)):\n",
    "        for sent in doc.sents:\n",
    "            s_start = sent.start_char\n",
    "            s_end = sent.end_char\n",
    "            t_start = test_doc[i]['start']\n",
    "            t_end = test_doc[i]['end']\n",
    "            if(s_start >= t_start-3 and s_end <= t_end+3):\n",
    "                if(s_start >= t_start-3 and s_start <= t_start+3 and s_end >= t_end-3 and s_end <= t_end+3):\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    fp+=1\n",
    "\n",
    "            elif(s_start <= t_end and s_start>=t_start and s_end >=t_end):\n",
    "                fp+=1\n",
    "            elif(i!=len(test_doc)-1 and s_start >= t_end and s_start < test_doc[i+1]['start'] and s_end <= test_doc[i+1]['end']):\n",
    "                fp+=1\n",
    "                \n",
    "    score_dict = {}\n",
    "    fn = len(test_doc) - tp\n",
    "    tp_total += tp\n",
    "    fp_total += fp\n",
    "    fn_total += fn\n",
    "    doc_precision = tp / (tp+fp)\n",
    "    doc_recall = tp / (tp+fn)\n",
    "    score_dict = {\"File\": train_doc_list[index],\n",
    "                 \"Precision\": doc_precision,\n",
    "                 \"Recall\": doc_recall}\n",
    "    score_list.append(score_dict)\n",
    "\n",
    "\n",
    "        \n",
    "#    print(\"File\",train_doc_list[index], \"P\", doc_precision, \"R\", doc_recall, \"F1\", doc_f1_score)\n",
    "#     print(\"File\",train_doc_list[index], \"TP\", tp, \"FP\", fp, \"FN\", fn)\n",
    "print(\"Total\", tp_total, fp_total, fn_total)\n",
    "\n",
    "precision = tp_total / (tp_total+fp_total)\n",
    "recall = tp_total / (tp_total+fn_total)\n",
    "f1_score = 2 * precision * recall/(precision+recall)\n",
    "\n",
    "print(f\"Precision: {precision}\\n Recall: {recall}\\n F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7d059f-db60-4ed4-909d-af82f6f24c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_scores = sorted(score_list, key=lambda k: k['Precision'])[0:3]\n",
    "recall_scores = sorted(score_list, key=lambda k: k['Recall'])[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aad5ec7-12b0-43d2-bcfb-9cd615049123",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(precision_scores)\n",
    "print(recall_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8691a86e-9342-4d04-9a15-02e778964999",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_doc_list = ['60b606d7f8611168dd279d16', '60b606d9f8611168dd279d44', '60b606d8f8611168dd279d2f', '60b606cbf8611168dd279cd1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ddb158-906f-4f1a-9ad3-e737c689a953",
   "metadata": {},
   "source": [
    "### Worst Performing Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb21712-9b04-4d27-bd1e-643d08164bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_total = 0\n",
    "fp_total = 0\n",
    "fn_total = 0\n",
    "\n",
    "worst_score_list = [] \n",
    "\n",
    "for index in range(len(new_doc_list)):\n",
    "    #print('@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@')\n",
    "    test_doc = []\n",
    "    for s in train_spans_new:\n",
    "        if(s['document']==new_doc_list[index]): \n",
    "            test_doc.append(s)\n",
    "    len_ann = len(test_doc)\n",
    "    document_txt = documents_by_id[new_doc_list[index]]['plainText']\n",
    "    doc = nlp(document_txt)\n",
    "    test_doc = sorted(test_doc, key=lambda k: k['start'])\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "\n",
    "    for i in range(len(test_doc)):\n",
    "#         print('---------------------------------------')\n",
    "#         print(\"TRUE\", test_doc[i]['start'], test_doc[i]['end'], test_doc[i]['txt'])\n",
    "        for sent in doc.sents:\n",
    "            s_start = sent.start_char\n",
    "            s_end = sent.end_char\n",
    "            t_start = test_doc[i]['start']\n",
    "            t_end = test_doc[i]['end']\n",
    "            if(s_start >= t_start-3 and s_end <= t_end+3):\n",
    "                if(s_start >= t_start-3 and s_start <= t_start+3 and s_end >= t_end-3 and s_end <= t_end+3):\n",
    "                    tp += 1\n",
    "#                     print(\"********* TP1\")\n",
    "#                     print(sent.text)\n",
    "#                     print(\"sent\", s_start, s_end)\n",
    "                else:\n",
    "                    fp+=1\n",
    "                    #internal sentences\n",
    "#                     print(\"####### FP1\")\n",
    "#                     print(sent.text)\n",
    "#                     print(\"sent\", s_start, s_end)\n",
    "\n",
    "            elif(s_start <= t_end and s_start>=t_start and s_end >=t_end):\n",
    "                fp+=1\n",
    "                #start inside end outside\n",
    "#                 print(\"####### FP2\")\n",
    "#                 print(sent.text)\n",
    "#                 print(\"sent\", s_start, s_end)\n",
    "\n",
    "            elif(i!=len(test_doc)-1 and s_start >= t_end and s_start < test_doc[i+1]['start'] and s_end <= test_doc[i+1]['end']):\n",
    "                fp+=1\n",
    "                #in betweens\n",
    "#                 print(\"####### FP3\")\n",
    "#                 print(sent.text)\n",
    "#                 print(\"sent\", s_start, s_end)\n",
    "    worst_score_dict = {}            \n",
    "    fn = len_ann - tp\n",
    "    tp_total += tp\n",
    "    fp_total += fp\n",
    "    fn_total += fn\n",
    "    doc_precision = tp / (tp+fp)\n",
    "    doc_recall = tp / (tp+fn)\n",
    "    worst_score_dict = {\"File\": new_doc_list[index],\n",
    "             \"Precision\": doc_precision,\n",
    "             \"Recall\": doc_recall}\n",
    "    worst_score_list.append(worst_score_dict)\n",
    "        \n",
    "    #print(\"File\",new_doc_list[index], \"P\", doc_precision, \"R\", doc_recall, \"F1\", doc_f1_score)\n",
    "    #print(\"File\",new_doc_list[index], \"TP\", tp, \"FP\", fp, \"FN\", fn)\n",
    "#print(\"Total\", tp_total, fp_total, fn_total)\n",
    "\n",
    "precision = tp_total / (tp_total+fp_total)\n",
    "recall = tp_total / (tp_total+fn_total)\n",
    "f1_score = 2 * precision * recall/(precision+recall)\n",
    "\n",
    "print(f\"Worst Precision: {precision}\\n Recall: {recall}\\n F1 Score: {f1_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826247b6-d2c7-4cfb-909c-74696f3bc10f",
   "metadata": {},
   "source": [
    "### Spacy extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d897d5-8b54-4742-ae4c-4b9c58d5d6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://blog.ceshine.net/post/spacy-sentencizer/\n",
    "from spacy.language import Language\n",
    "@Language.component(\"set_custom_boundaries\")\n",
    "def set_custom_boundaries(doc):\n",
    "    for i, token in enumerate(doc):\n",
    "        if token.text in (\"’s\", \"'s\"):\n",
    "            doc[i].is_sent_start = False\n",
    "        elif token.text in (\"“\", \"‘\") and i < len(doc) - 1:\n",
    "            # opening quote\n",
    "            doc[i+1].is_sent_start = False\n",
    "        elif token.text in (\"”\", \"’\"):\n",
    "            # closing quote\n",
    "            doc[i].is_sent_start = False\n",
    "        elif token.text == \"\\t\":\n",
    "            doc[i].is_sent_start = False\n",
    "        elif token.text in (\" \",\"  \",\"   \",\"    \"):\n",
    "            doc[i].is_sent_start = False\n",
    "        elif token.text == \"\\n\":\n",
    "            doc[i].is_sent_start = False\n",
    "        elif token.text == \"\\r\":\n",
    "            doc[i].is_sent_start = False\n",
    "        elif token.text == \"DC.\":\n",
    "            doc[i].is_sent_start = False\n",
    "        elif token.text in (\"Archive\",\"DOCKET\",\"NO.\",\"DATE\",\"(\",\")\"):\n",
    "            doc[i].is_sent_start = False\n",
    "        elif token.text in (\": \"):\n",
    "            doc[i+1].is_sent_start = False\n",
    "        \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd03e468-1dd1-4baf-8e79-768b2f954ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.add_pipe(\"set_custom_boundaries\", before=\"parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8991bd-7bd3-4911-8e31-16e89591a1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#New Worst ones\n",
    "\n",
    "tp_total = 0\n",
    "fp_total = 0\n",
    "fn_total = 0\n",
    "\n",
    "worst_score_list = [] \n",
    "\n",
    "for index in range(len(new_doc_list)):\n",
    "    #print('@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@')\n",
    "    test_doc = []\n",
    "    for s in train_spans_new:\n",
    "        if(s['document']==new_doc_list[index]): \n",
    "            test_doc.append(s)\n",
    "    len_ann = len(test_doc)\n",
    "    document_txt = documents_by_id[new_doc_list[index]]['plainText']\n",
    "    doc = nlp(document_txt)\n",
    "    test_doc = sorted(test_doc, key=lambda k: k['start'])\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "\n",
    "    for i in range(len(test_doc)):\n",
    "#         print('---------------------------------------')\n",
    "#         print(\"TRUE\", test_doc[i]['start'], test_doc[i]['end'], test_doc[i]['txt'])\n",
    "        for sent in doc.sents:\n",
    "            s_start = sent.start_char\n",
    "            s_end = sent.end_char\n",
    "            t_start = test_doc[i]['start']\n",
    "            t_end = test_doc[i]['end']\n",
    "            if(s_start >= t_start-3 and s_end <= t_end+3):\n",
    "                if(s_start >= t_start-3 and s_start <= t_start+3 and s_end >= t_end-3 and s_end <= t_end+3):\n",
    "                    tp += 1\n",
    "#                     print(\"********* TP1\")\n",
    "#                     print(sent.text)\n",
    "#                     print(\"sent\", s_start, s_end)\n",
    "                else:\n",
    "                    fp+=1\n",
    "                    #internal sentences\n",
    "#                     print(\"####### FP1\")\n",
    "#                     print(sent.text)\n",
    "#                     print(\"sent\", s_start, s_end)\n",
    "\n",
    "            elif(s_start <= t_end and s_start>=t_start and s_end >=t_end):\n",
    "                fp+=1\n",
    "                #start inside end outside\n",
    "#                 print(\"####### FP2\")\n",
    "#                 print(sent.text)\n",
    "#                 print(\"sent\", s_start, s_end)\n",
    "\n",
    "            elif(i!=len(test_doc)-1 and s_start >= t_end and s_start < test_doc[i+1]['start'] and s_end <= test_doc[i+1]['end']):\n",
    "                fp+=1\n",
    "                #in betweens\n",
    "#                 print(\"####### FP3\")\n",
    "#                 print(sent.text)\n",
    "#                 print(\"sent\", s_start, s_end)\n",
    "    worst_score_dict = {}            \n",
    "    fn = len_ann - tp\n",
    "    tp_total += tp\n",
    "    fp_total += fp\n",
    "    fn_total += fn\n",
    "    doc_precision = tp / (tp+fp)\n",
    "    doc_recall = tp / (tp+fn)\n",
    "    worst_score_dict = {\"File\": new_doc_list[index],\n",
    "             \"Precision\": doc_precision,\n",
    "             \"Recall\": doc_recall}\n",
    "    worst_score_list.append(worst_score_dict)\n",
    "        \n",
    "    #print(\"File\",new_doc_list[index], \"P\", doc_precision, \"R\", doc_recall, \"F1\", doc_f1_score)\n",
    "    #print(\"File\",new_doc_list[index], \"TP\", tp, \"FP\", fp, \"FN\", fn)\n",
    "    #print(\"Total\", tp_total, fp_total, fn_total)\n",
    "\n",
    "    \n",
    "precision = tp_total / (tp_total+fp_total)\n",
    "recall = tp_total / (tp_total+fn_total)\n",
    "f1_score = 2 * precision * recall/(precision+recall)\n",
    "\n",
    "print(f\"Worst Precision: {precision}\\n Recall: {recall}\\n F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70ba36e-6d13-4505-a5b4-b32989187eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f148af42-7262-4e97-9676-418cd48f0a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Data\n",
    "\n",
    "tp_total = 0\n",
    "fp_total = 0\n",
    "fn_total = 0\n",
    "\n",
    "score_list = [] \n",
    "\n",
    "for index in range(len(train_doc_list)):\n",
    "    test_doc = []\n",
    "    for s in train_spans_new:\n",
    "        if(s['document']==train_doc_list[index]):\n",
    "            test_doc.append(s)\n",
    "   \n",
    "    document_txt = documents_by_id[train_doc_list[index]]['plainText']\n",
    "    doc = nlp(document_txt)\n",
    "    test_doc = sorted(test_doc, key=lambda k: k['start'])\n",
    "    \n",
    "    tp = 0\n",
    "    fp = 0\n",
    "\n",
    "    for i in range(len(test_doc)):\n",
    "        for sent in doc.sents:\n",
    "            s_start = sent.start_char\n",
    "            s_end = sent.end_char\n",
    "            t_start = test_doc[i]['start']\n",
    "            t_end = test_doc[i]['end']\n",
    "            if(s_start >= t_start-3 and s_end <= t_end+3):\n",
    "                if(s_start >= t_start-3 and s_start <= t_start+3 and s_end >= t_end-3 and s_end <= t_end+3):\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    fp+=1\n",
    "\n",
    "            elif(s_start <= t_end and s_start>=t_start and s_end >=t_end):\n",
    "                fp+=1\n",
    "            elif(i!=len(test_doc)-1 and s_start >= t_end and s_start < test_doc[i+1]['start'] and s_end <= test_doc[i+1]['end']):\n",
    "                fp+=1\n",
    "                \n",
    "    score_dict = {}\n",
    "    fn = len(test_doc) - tp\n",
    "    tp_total += tp\n",
    "    fp_total += fp\n",
    "    fn_total += fn\n",
    "    doc_precision = tp / (tp+fp)\n",
    "    doc_recall = tp / (tp+fn)\n",
    "    score_dict = {\"File\": train_doc_list[index],\n",
    "                 \"Precision\": doc_precision,\n",
    "                 \"Recall\": doc_recall}\n",
    "    score_list.append(score_dict)\n",
    "\n",
    "\n",
    "        \n",
    "#    print(\"File\",train_doc_list[index], \"P\", doc_precision, \"R\", doc_recall, \"F1\", doc_f1_score)\n",
    "#     print(\"File\",train_doc_list[index], \"TP\", tp, \"FP\", fp, \"FN\", fn)\n",
    "    \n",
    "print(\"Total\", tp_total, fp_total, fn_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f8ed47-43c5-4adc-ac7d-b5c4595aa16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = tp_total / (tp_total+fp_total)\n",
    "recall = tp_total / (tp_total+fn_total)\n",
    "f1_score = 2 * precision * recall/(precision+recall)\n",
    "\n",
    "print(f\"Precision: {precision}\\n Recall: {recall}\\n F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dee350-9569-433e-9aec-e9c2cbbd067b",
   "metadata": {},
   "source": [
    "### Luima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c0b2f5-b1ca-4991-85ad-ecdb690971e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Worst files with sbd\n",
    "tp_total = 0\n",
    "fp_total = 0\n",
    "fn_total = 0\n",
    "\n",
    "worst_score_list = [] \n",
    "\n",
    "for index in range(len(new_doc_list)):\n",
    "    #print('@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@')\n",
    "    #print(new_doc_list[index])\n",
    "    test_doc = []\n",
    "    for s in train_spans_new:\n",
    "        if(s['document']==new_doc_list[index]): \n",
    "            test_doc.append(s)\n",
    "    len_ann = len(test_doc)\n",
    "    document_txt = documents_by_id[new_doc_list[index]]['plainText']\n",
    "    sentences = sbd.text2sentences(document_txt, offsets=False)\n",
    "    offsets = sbd.text2sentences(document_txt, offsets=True)\n",
    "    test_doc = sorted(test_doc, key=lambda k: k['start'])\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "\n",
    "    for i in range(len(test_doc)):\n",
    "        #print('---------------------------------------')\n",
    "        #print(\"TRUE\", test_doc[i]['start'], test_doc[i]['end'], test_doc[i]['txt'])\n",
    "        for j in range(len(sentences)):\n",
    "            s_start = offsets[j][0]\n",
    "            s_end = offsets[j][1]\n",
    "            t_start = test_doc[i]['start']\n",
    "            t_end = test_doc[i]['end']\n",
    "            if(s_start >= t_start-3 and s_end <= t_end+3):\n",
    "                if(s_start >= t_start-3 and s_start <= t_start+3 and s_end >= t_end-3 and s_end <= t_end+3):\n",
    "                    tp += 1\n",
    "#                     print(\"********* TP1\")\n",
    "#                     print(sentences[j])\n",
    "#                     print(\"sent\", s_start, s_end)\n",
    "                else:\n",
    "                    fp+=1\n",
    "                    #internal sentences\n",
    "#                     print(\"####### FP1\")\n",
    "#                     print(sentences[j])\n",
    "#                     print(\"sent\", s_start, s_end)\n",
    "\n",
    "            elif(s_start <= t_end and s_start>=t_start and s_end >=t_end):\n",
    "                fp+=1\n",
    "                #start inside end outside\n",
    "#                 print(\"####### FP2\")\n",
    "#                 print(sentences[j])\n",
    "#                 print(\"sent\", s_start, s_end)\n",
    "\n",
    "            elif(i!=len(test_doc)-1 and s_start >= t_end and s_start < test_doc[i+1]['start'] and s_end <= test_doc[i+1]['end']):\n",
    "                fp+=1\n",
    "                #in betweens\n",
    "#                 print(\"####### FP3\")\n",
    "#                 print(sentences[j])\n",
    "#                 print(\"sent\", s_start, s_end)\n",
    "    worst_score_dict = {}            \n",
    "    fn = len_ann - tp\n",
    "    tp_total += tp\n",
    "    fp_total += fp\n",
    "    fn_total += fn\n",
    "    doc_precision = tp / (tp+fp)\n",
    "    doc_recall = tp / (tp+fn)\n",
    "    worst_score_dict = {\"File\": new_doc_list[index],\n",
    "             \"Precision\": doc_precision,\n",
    "             \"Recall\": doc_recall}\n",
    "    worst_score_list.append(worst_score_dict)\n",
    "        \n",
    "    #print(\"File\",new_doc_list[index], \"P\", doc_precision, \"R\", doc_recall, \"F1\", doc_f1_score)\n",
    "    #print(\"File\",new_doc_list[index], \"TP\", tp, \"FP\", fp, \"FN\", fn)\n",
    "    #print(\"Total\", tp_total, fp_total, fn_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1a897e-2be9-4be9-a3ad-ef495d838b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = tp_total / (tp_total+fp_total)\n",
    "recall = tp_total / (tp_total+fn_total)\n",
    "f1_score = 2 * precision * recall/(precision+recall)\n",
    "\n",
    "print(f\"Precision: {precision}\\n Recall: {recall}\\n F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29725549-5065-4ffe-a39c-e79137621d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44be8da-5da1-4dc4-910b-f4666d421972",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Training Data\n",
    "tp_total = 0\n",
    "fp_total = 0\n",
    "fn_total = 0\n",
    "\n",
    "score_list = [] \n",
    "\n",
    "for index in range(len(train_doc_list)):\n",
    "    test_doc = []\n",
    "    for s in train_spans_new:\n",
    "        if(s['document']==train_doc_list[index]):\n",
    "            test_doc.append(s)\n",
    "   \n",
    "    document_txt = documents_by_id[train_doc_list[index]]['plainText']\n",
    "    sentences = sbd.text2sentences(document_txt, offsets=False)\n",
    "    offsets = sbd.text2sentences(document_txt, offsets=True)\n",
    "    test_doc = sorted(test_doc, key=lambda k: k['start'])\n",
    "    \n",
    "    tp = 0\n",
    "    fp = 0\n",
    "\n",
    "    for i in range(len(test_doc)):\n",
    "#         print('---------------------------------------')\n",
    "#         print(\"TRUE\", test_doc[i]['start'], test_doc[i]['end'], test_doc[i]['txt'])\n",
    "        for j in range(len(sentences)):\n",
    "            s_start = offsets[j][0]\n",
    "            s_end = offsets[j][1]\n",
    "            t_start = test_doc[i]['start']\n",
    "            t_end = test_doc[i]['end']\n",
    "            if(s_start >= t_start-3 and s_end <= t_end+3):\n",
    "                if(s_start >= t_start-3 and s_start <= t_start+3 and s_end >= t_end-3 and s_end <= t_end+3):\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    fp+=1\n",
    "#                     print(\"####### FP1\")\n",
    "#                     print(sentences[j])\n",
    "#                     print(\"sent\", s_start, s_end)\n",
    "\n",
    "            elif(s_start <= t_end and s_start>=t_start and s_end >=t_end):\n",
    "                fp+=1\n",
    "#                 print(\"####### FP2\")\n",
    "#                 print(sentences[j])\n",
    "#                 print(\"sent\", s_start, s_end)\n",
    "            elif(i!=len(test_doc)-1 and s_start >= t_end and s_start < test_doc[i+1]['start'] and s_end <= test_doc[i+1]['end']):\n",
    "                fp+=1\n",
    "#                 print(\"####### FP3\")\n",
    "#                 print(sentences[j])\n",
    "#                 print(\"sent\", s_start, s_end)\n",
    "                \n",
    "    score_dict = {}\n",
    "    fn = len(test_doc) - tp\n",
    "    tp_total += tp\n",
    "    fp_total += fp\n",
    "    fn_total += fn\n",
    "    doc_precision = tp / (tp+fp)\n",
    "    doc_recall = tp / (tp+fn)\n",
    "    score_dict = {\"File\": train_doc_list[index],\n",
    "                 \"Precision\": doc_precision,\n",
    "                 \"Recall\": doc_recall}\n",
    "    score_list.append(score_dict)\n",
    "\n",
    "\n",
    "        \n",
    "#    print(\"File\",train_doc_list[index], \"P\", doc_precision, \"R\", doc_recall, \"F1\", doc_f1_score)\n",
    "#print(\"File\",train_doc_list[index], \"TP\", tp, \"FP\", fp, \"FN\", fn)\n",
    "    \n",
    "#print(\"Total\", tp_total, fp_total, fn_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecb5248-b32e-4f97-872f-ec3d8077b15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = tp_total / (tp_total+fp_total)\n",
    "recall = tp_total / (tp_total+fn_total)\n",
    "f1_score = 2 * precision * recall/(precision+recall)\n",
    "\n",
    "print(f\"Precision: {precision}\\n Recall: {recall}\\n F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f7992a-0bf0-4530-9055-b1342d5ea4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_files = os.listdir(\"./unlabeled/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db9e47b-66c0-4ded-ba23-a0b3477de41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_list = []\n",
    "file_no = 1\n",
    "for file in unlabeled_files:\n",
    "    unlabeled_txt = open(f\"./unlabeled/{file}\", \"r\").read()\n",
    "    unlabeled_sentences = sbd.text2sentences(unlabeled_txt, offsets=False)\n",
    "    #unlabeled_offsets = sbd.text2sentences(unlabeled_txt, offsets=True)\n",
    "    count = len(unlabeled_sentences)\n",
    "    hist_dict = {\"file_name\": file,\n",
    "                \"sent_count\": count,\n",
    "                \"sentences\": unlabeled_sentences}\n",
    "    \n",
    "    hist_list.append(hist_dict)\n",
    "    #unlabeled_txt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b349d92b-283c-4dc1-b428-f3d6583abc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(hist_list)\n",
    "print(hist_df['sent_count'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d9048f-125e-4909-b743-0927c76bd473",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df.to_csv('hist_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64f626c-7d29-4eeb-b4bf-f737a30a8318",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SENTENCE HISTOGRAM\n",
    "fig_prop()\n",
    "sns.histplot(data = hist_df, x = \"sent_count\", binwidth=1)\n",
    "plt.xlabel('Number of sentences')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07ba81c-2c26-4a2e-841e-6079aaf69f48",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5169b7-3e8a-4e6d-968f-27a5a1e87852",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "special_cases = ['Vet. App.','Fed. Cir.']\n",
    "nlp.tokenizer.add_special_case('Vet. App.', [{ORTH: 'Vet. App.'}])\n",
    "nlp.tokenizer.add_special_case('Fed. Cir.', [{ORTH: 'Fed. Cir.'}])\n",
    "\n",
    "def spacy_tokenize(txt):\n",
    "    doc = nlp(txt)\n",
    "    tokens = list(doc)\n",
    "    clean_tokens = []\n",
    "    for i in range(len(tokens)):\n",
    "        t = tokens[i]\n",
    "        #print(t.pos_, t.text)\n",
    "        #print(i, len(tokens))\n",
    "        if(i != len(tokens) - 1):\n",
    "            t_next = tokens[i+1]\n",
    "        else: t_next = None\n",
    "        if(t_next!=None and t_next.pos_=='PART' and re.search(r'\\'', t_next.text)):\n",
    "            t_combined = t.text + t_next.text\n",
    "            t_combined = re.sub(r'\\W','',t_combined).lower()\n",
    "            clean_tokens.append(t_combined)\n",
    "            i+=1           \n",
    "        elif t.pos_ == 'PUNCT':\n",
    "            pass\n",
    "        elif t.text in special_cases:\n",
    "            clean_tokens.append(t.lemma_.lower())\n",
    "        elif (t.text[0].isalpha() == False and t.is_digit==False and t.is_upper == False):\n",
    "            pass            \n",
    "        elif t.pos_ == 'NUM':\n",
    "            clean_tokens.append(f'<NUM{len(t)}>')\n",
    "        else:\n",
    "            lemma = t.lemma_\n",
    "            lemma = re.sub(r'\\W','',lemma)\n",
    "            lemma =lemma.lower()\n",
    "            clean_tokens.append(lemma)\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859f7abe-8c39-42c3-ba1e-69322776b51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_basic_1 = 'In sum, as the preponderance of the evidence is against the Veteran\\'s claim, his appeal must be denied.'\n",
    "example_cit_1 = 'Smith v. Gober, 14 Vet. App. 227 (2000), aff\\'d 281 F.3d 1384 (Fed. Cir. 2002); \\tDela Cruz v. Principi, 15 Vet. App. 143 (2001); see also Quartuccio v. Principi, 16 Vet. App. 183 (2002).'\n",
    "example_rule_1 = '\"To establish a right to compensation for a present disability, a Veteran must show: \"(1) the existence of a present disability; (2) in-service incurrence or aggravation of a disease or injury; and (3) a causal relationship between the present disability and the disease or injury incurred or aggravated during service\"-the so-called \"nexus\" requirement.\"'\n",
    "example_mixed_1 = 'In Dingess v. Nicholson, 19 Vet. App. 473 (2006), the U.S. Court of Appeals for Veterans Claims held that, upon receipt of an application for a service-connection claim, 38 U.S.C.A. � 5103(a) and 38 C.F.R. � 3.159(b) require VA to provide the claimant with notice that a disability rating and an effective date for the award of benefits will be assigned if service connection is awarded. '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeef1af4-7555-4d64-8e75-1bbb54ede88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_tokenize(example_mixed_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c457eac-f787-4c5a-baeb-7e7eaf50e7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_list = []\n",
    "for i in range(len(hist_df)):\n",
    "    for sent in hist_df['sentences'][i]:        \n",
    "        tokenized = spacy_tokenize(sent)\n",
    "            #print(s)\n",
    "            #print(tokenized)\n",
    "        token_dict = {\"File\": hist_df['file_name'][i],\n",
    "                     \"Sentence\": sent,\n",
    "                     \"Tokens\": tokenized,\n",
    "                     \"Token_number\": len(tokenized)}\n",
    "        token_list.append(token_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e52eee-154c-4bc7-b78f-e96568f1d6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_list_df = pd.DataFrame(token_list)\n",
    "token_list_df.to_csv('token_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbacec6-b31a-4a06-bd15-e7334ba222ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(token_list_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087068f0-6be8-4c83-8b31-04b12079dda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TOKEN HISTOGRAM\n",
    "fig_prop()\n",
    "sns.histplot(data = token_list_df, x = 'Token_number', binwidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729188b5-a06e-45aa-b67d-30d853e091e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_token_list_df = token_list_df\n",
    "random_token_list_df = random_token_list_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4870fe8-c7e1-4477-ad0f-4b4a3310049b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file = open('random_sentences.txt', 'a')\n",
    "\n",
    "def make_file(Tokens):\n",
    "    line = ' '.join(Tokens)\n",
    "    line = line + '\\n'\n",
    "    new_file.write(line)\n",
    "\n",
    "random_token_list_df[random_token_list_df.Token_number>5].Tokens.apply(make_file)\n",
    "\n",
    "new_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa4312b-80a4-49d9-8915-04151177810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sentences = open('random_sentences.txt', 'r')\n",
    "token_list_df = pd.read_csv('token_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd7b2ee-a294-4040-a9d8-34e1c2ad136d",
   "metadata": {},
   "source": [
    "### Train FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d0175c-c70f-4c60-a742-3558c54a2dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_unsupervised(input = 'random_sentences.txt', dim = 100, minCount = 20, epoch = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5129a12-9fa4-47c7-b54e-31917310df11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"result_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e7be42-f1f4-4113-b124-4e3ca7f53d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_model = fasttext.load_model(\"result_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66d453b-7355-4829-8d32-d323cab46cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = result_model.get_words(on_unicode_error='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b9593a-47cc-4c6b-bb41-ec9287fb756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = len(words)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6171355-57c6-47ef-9175-a86d44c0c3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = [\"veteran\",\"vet\",\"service\",\"cause\",\"caused\",\"remanded\",\"vietnam\",\"see\",\"denied\",\"decision\",\"board\",\"physician\",\"evidence\",\"claim\",\"pain\",\"under\",\"appeal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269df541-e280-46f3-8721-0e0346721d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = []\n",
    "for word in word_list:\n",
    "    nearest = model.get_nearest_neighbors(word)\n",
    "    neigh_dict = {\"word\":word,\n",
    "                    \"neighbours\": nearest}\n",
    "    neighbors.append(neigh_dict)\n",
    "    \n",
    "neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec266520-b49f-4d9c-aca0-06afe94bd61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neigh = pd.DataFrame(neighbors)\n",
    "df_neigh.to_csv('nearest_neighbors.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e528fea4-4a64-4c80-9e65-df5e6a2a3da4",
   "metadata": {},
   "source": [
    "## TFIDF Featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d336e8a-4e7f-475a-8e29-f551d5518c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suboptimal: tokenizer gets called twice\n",
    "spacy_tfidf_vectorizer = TfidfVectorizer(tokenizer=spacy_tokenize,\n",
    "                                         min_df=3,\n",
    "                                         ngram_range=(1,1))\n",
    "spacy_tfidf_vectorizer = spacy_tfidf_vectorizer.fit(train_spans_txt)\n",
    "tfidf_features_spacy = spacy_tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcb4dbd-7654-44da-b86d-0f21288e0d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf_spacy = spacy_tfidf_vectorizer.transform(train_spans_txt).toarray()\n",
    "dev_tfidf_spacy = spacy_tfidf_vectorizer.transform(dev_spans_txt).toarray()\n",
    "test_tfidf_spacy = spacy_tfidf_vectorizer.transform(test_spans_txt).toarray()\n",
    "\n",
    "train_spans_labels = np.array([s['type'] for s in train_spans_new])\n",
    "dev_spans_labels = np.array([s['type'] for s in dev_spans_new])\n",
    "test_spans_labels = np.array([s['type'] for s in test_spans_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09027356-5a11-4b1e-ab77-dc21d5029490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE VECTORIZER\n",
    "joblib.dump(spacy_tfidf_vectorizer, 'spacy_vectorizer.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ce6ed6-6e6e-47e0-a0ca-1b8a6c32f067",
   "metadata": {},
   "source": [
    "### MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713a50af-f02c-4908-bebc-21fe8b61cb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL WITHOUT EMBEDDING\n",
    "def no_make_feature_vectors_and_labels(spans, vectorizer):\n",
    "    # function takes long to execute\n",
    "    # note: we un-sparse the matrix here to be able to manipulate it\n",
    "    tfidf = spacy_tfidf_vectorizer.transform([s['txt'] for s in spans]).toarray()\n",
    "    starts_normalized = np.array([s['start_normalized'] for s in spans])\n",
    "    num_tokens_normalized = np.array([(s['tokens_count']-train_tokens_mean)/train_tokens_std for s in spans])\n",
    "    \n",
    "    #avg_vec = np.array([s['average_vec'] for s in spans])\n",
    "    y = np.array([s['type'] for s in spans])\n",
    "    X = np.concatenate((tfidf, np.expand_dims(starts_normalized, axis=1), np.expand_dims(num_tokens_normalized, axis=1)), axis=1)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "train_X, train_y = no_make_feature_vectors_and_labels(train_spans_new, spacy_tfidf_vectorizer)\n",
    "dev_X, dev_y = no_make_feature_vectors_and_labels(dev_spans_new, spacy_tfidf_vectorizer)\n",
    "test_X, test_y = no_make_feature_vectors_and_labels(test_spans_new, spacy_tfidf_vectorizer)\n",
    "\n",
    "print(f'{train_X.shape} {train_y.shape}')\n",
    "print(f'{dev_X.shape} {dev_y.shape}')\n",
    "print(f'{test_X.shape} {test_y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf527dca-cdd6-49e8-968d-1bb8b2204867",
   "metadata": {},
   "source": [
    "### Linear Support Vector Machine Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dce6795-91e8-4918-a61f-e6b4c93278c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearSVC(random_state = 0)\n",
    "clf = clf.fit(train_X, train_y)\n",
    "\n",
    "print('TRAIN:\\n'+classification_report(train_spans_labels, clf.predict(train_X)))\n",
    "print('DEV:\\n'+classification_report(dev_spans_labels, clf.predict(dev_X)))\n",
    "\n",
    "plot_confusion_matrix(dev_spans_labels, clf.predict(dev_X), classes=list(clf.classes_),\n",
    "                      title='Confusion matrix for training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bd2ea0-c38f-4c20-8bb4-aca706ecbfff",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb54c03b-f60e-4f14-af64-dca1bc454198",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state = 0)\n",
    "clf = clf.fit(train_X, train_y)\n",
    "\n",
    "print('TRAIN:\\n'+classification_report(train_spans_labels, clf.predict(train_X)))\n",
    "print('DEV:\\n'+classification_report(dev_spans_labels, clf.predict(dev_X)))\n",
    "\n",
    "plot_confusion_matrix(dev_spans_labels, clf.predict(dev_X), classes=list(clf.classes_),\n",
    "                      title='Confusion matrix for training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16effc16-a6a5-40b1-ba4f-927f30400037",
   "metadata": {},
   "source": [
    "### Radial kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6350d8df-2e79-43e1-a182-f772d9e0821f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter=None, gamma='scale'\n",
    "clf = SVC(kernel = 'rbf', random_state = 0)\n",
    "clf = clf.fit(train_X, train_y)\n",
    "\n",
    "print('TRAIN:\\n'+classification_report(train_spans_labels, clf.predict(train_X)))\n",
    "print('DEV:\\n'+classification_report(dev_spans_labels, clf.predict(dev_X)))\n",
    "\n",
    "plot_confusion_matrix(dev_spans_labels, clf.predict(dev_X), classes=list(clf.classes_),\n",
    "                      title='Confusion matrix for training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1c81f8-0669-435f-ad60-2f095b2069c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter: gamma = 'auto'\n",
    "clf = SVC(kernel = 'rbf', gamma = 'auto', random_state = 0)\n",
    "clf = clf.fit(train_X, train_y)\n",
    "\n",
    "print('TRAIN:\\n'+classification_report(train_spans_labels, clf.predict(train_X)))\n",
    "print('DEV:\\n'+classification_report(dev_spans_labels, clf.predict(dev_X)))\n",
    "\n",
    "plot_confusion_matrix(dev_spans_labels, clf.predict(dev_X), classes=list(clf.classes_),\n",
    "                      title='Confusion matrix for training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bdf7af-374c-4e1a-9401-fb67b32c5269",
   "metadata": {},
   "source": [
    "### Polynomial kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c54bff-1a44-4cff-b01a-de40dab15bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter: None, degree = 3\n",
    "clf = SVC(kernel = 'poly', random_state = 0)\n",
    "clf = clf.fit(train_X, train_y)\n",
    "\n",
    "print('TRAIN:\\n'+classification_report(train_spans_labels, clf.predict(train_X)))\n",
    "print('DEV:\\n'+classification_report(dev_spans_labels, clf.predict(dev_X)))\n",
    "\n",
    "plot_confusion_matrix(dev_spans_labels, clf.predict(dev_X), classes=list(clf.classes_),\n",
    "                      title='Confusion matrix for training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cbf60d-0aa5-4fdd-a7b7-6e16e809a639",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter: degree = 2\n",
    "clf = SVC(kernel = 'poly', degree = 2, random_state = 0)\n",
    "clf = clf.fit(train_X, train_y)\n",
    "\n",
    "print('TRAIN:\\n'+classification_report(train_spans_labels, clf.predict(train_X)))\n",
    "print('DEV:\\n'+classification_report(dev_spans_labels, clf.predict(dev_X)))\n",
    "\n",
    "plot_confusion_matrix(dev_spans_labels, clf.predict(dev_X), classes=list(clf.classes_),\n",
    "                      title='Confusion matrix for training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca3ccd2-5e03-445f-a3ea-a02e97faf4d1",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ded6ed6-e878-48fd-a8de-e0793dcde9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter: max_depth = 20\n",
    "\n",
    "clf = RandomForestClassifier(max_depth = 20, random_state = 0)\n",
    "clf = clf.fit(train_X, train_y)\n",
    "\n",
    "print('TRAIN:\\n'+classification_report(train_spans_labels, clf.predict(train_X)))\n",
    "print('DEV:\\n'+classification_report(dev_spans_labels, clf.predict(dev_X)))\n",
    "\n",
    "plot_confusion_matrix(dev_spans_labels, clf.predict(dev_X), classes=list(clf.classes_),\n",
    "                      title='Confusion matrix for training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130d1f87-c515-41ab-83b9-c78c4d71f8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter: max_depth = None\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(max_depth = None, random_state = 0)\n",
    "clf = clf.fit(train_X, train_y)\n",
    "\n",
    "print('TRAIN:\\n'+classification_report(train_spans_labels, clf.predict(train_X)))\n",
    "print('DEV:\\n'+classification_report(dev_spans_labels, clf.predict(dev_X)))\n",
    "\n",
    "plot_confusion_matrix(dev_spans_labels, clf.predict(dev_X), classes=list(clf.classes_),\n",
    "                      title='Confusion matrix for training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd69361c-d466-4a39-85b9-44d101347abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter: n_estimators = 200\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 200, max_depth = 12, random_state = 0)\n",
    "clf = clf.fit(train_X, train_y)\n",
    "\n",
    "print('TRAIN:\\n'+classification_report(train_spans_labels, clf.predict(train_X)))\n",
    "print('DEV:\\n'+classification_report(dev_spans_labels, clf.predict(dev_X)))\n",
    "\n",
    "plot_confusion_matrix(dev_spans_labels, clf.predict(dev_X), classes=list(clf.classes_),\n",
    "                      title='Confusion matrix for training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa0da67-bc14-4426-8d26-0939e46d8f78",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4659fac-6369-45e5-a7f5-023c60cfdc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=12)\n",
    "clf = clf.fit(train_X, train_y)\n",
    "\n",
    "print('TRAIN:\\n'+classification_report(train_spans_labels, clf.predict(train_X)))\n",
    "print('DEV:\\n'+classification_report(dev_spans_labels, clf.predict(dev_X)))\n",
    "\n",
    "plot_confusion_matrix(dev_spans_labels, clf.predict(dev_X), classes=list(clf.classes_),\n",
    "                      title='Confusion matrix for training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29534948-6032-499f-ad8d-12b2dd991e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter: max_depth = 22\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_depth=22)\n",
    "clf = clf.fit(train_X, train_y)\n",
    "\n",
    "print('TRAIN:\\n'+classification_report(train_spans_labels, clf.predict(train_X)))\n",
    "print('DEV:\\n'+classification_report(dev_spans_labels, clf.predict(dev_X)))\n",
    "\n",
    "plot_confusion_matrix(dev_spans_labels, clf.predict(dev_X), classes=list(clf.classes_),\n",
    "                      title='Confusion matrix for training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cec763-c3f5-4de4-b45d-3cade555b38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter: min_samples_split = 10\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(min_samples_split = 10)\n",
    "clf = clf.fit(train_X, train_y)\n",
    "\n",
    "print('TRAIN:\\n'+classification_report(train_spans_labels, clf.predict(train_X)))\n",
    "print('DEV:\\n'+classification_report(dev_spans_labels, clf.predict(dev_X)))\n",
    "\n",
    "plot_confusion_matrix(dev_spans_labels, clf.predict(dev_X), classes=list(clf.classes_),\n",
    "                      title='Confusion matrix for training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df702ac7-fc75-477c-a750-6b729adfb7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0914136-d5ea-48d4-93a0-f57382f011be",
   "metadata": {},
   "source": [
    "## Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2054fb8-4a49-4560-9d95-cb58778e3c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearSVC(random_state = 0)\n",
    "clf = clf.fit(train_X, train_y)\n",
    "\n",
    "print('TRAIN:\\n'+classification_report(train_spans_labels, clf.predict(train_X)))\n",
    "print('DEV:\\n'+classification_report(dev_spans_labels, clf.predict(dev_X)))\n",
    "plot_confusion_matrix(dev_spans_labels, clf.predict(dev_X), classes=list(clf.classes_),\n",
    "                      title='Confusion matrix for DEV data')\n",
    "\n",
    "print('TEST:\\n'+classification_report(test_spans_labels, clf.predict(test_X)))\n",
    "\n",
    "plot_confusion_matrix(test_spans_labels, clf.predict(test_X), classes=list(clf.classes_),\n",
    "                      title='Confusion matrix for TEST data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456260d5-1dff-4af0-9ffc-1ccf55effa35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a102833a-6a89-47ee-926d-dea240bff4cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ff14eb1-a159-41cf-98c0-3ab915916a07",
   "metadata": {},
   "source": [
    "## Word Embedding Featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa7a09a-6c28-433a-a3d1-6318e2315c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spans_add_spacy_tokens(spans):\n",
    "    for s in spans:\n",
    "        s['tokens_spacy'] = spacy_tokenize(s['txt'])\n",
    "        s['tokens_count'] = len(s['tokens_spacy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0073d5-efe8-4066-99b2-2921169148f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spans_add_spacy_tokens(train_spans_new)\n",
    "spans_add_spacy_tokens(test_spans_new)\n",
    "spans_add_spacy_tokens(dev_spans_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34c727d-e584-41bb-8c78-c92d8b7017b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spans_df = pd.DataFrame(train_spans_new)\n",
    "test_spans_df = pd.DataFrame(test_spans_new)\n",
    "dev_spans_df = pd.DataFrame(dev_spans_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be88a8b6-0762-4fcb-b520-1fab6cdbfd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens_mean = train_spans_df['tokens_count'].mean()\n",
    "train_tokens_std = train_spans_df['tokens_count'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abfcb0b-5ba3-43ec-b066-a0ff6cd452f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_tokens_mean)\n",
    "print(train_tokens_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d3feb6-58b2-4ca5-b616-43f03ce810b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vector_spans(spans):\n",
    "    for s in spans:\n",
    "        total_vec = np.zeros(100,)\n",
    "        total_tokens = s['tokens_count']\n",
    "        if(total_tokens != 0):\n",
    "            for t in s['tokens_spacy']:\n",
    "                word_vec = model.get_word_vector(t)\n",
    "                total_vec = np.add(total_vec, word_vec)\n",
    "            average_vec = total_vec / total_tokens\n",
    "            s['average_vec'] = average_vec\n",
    "        else:\n",
    "            s['average_vec'] = np.zeros(100,)\n",
    "            \n",
    "word_vector_spans(train_spans_new)\n",
    "word_vector_spans(test_spans_new)\n",
    "word_vector_spans(dev_spans_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbbaa73-a52c-4795-9c00-8e24c5e8675d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_vectors_and_labels(spans):\n",
    "    # function takes long to execute\n",
    "    # note: we un-sparse the matrix here to be able to manipulate it\n",
    "    #tfidf = spacy_tfidf_vectorizer.transform([s['txt'] for s in spans]).toarray()\n",
    "    starts_normalized = np.array([s['start_normalized'] for s in spans])\n",
    "    num_tokens_normalized = np.array([(s['tokens_count']-train_tokens_mean)/train_tokens_std for s in spans])\n",
    "    \n",
    "    avg_vec = np.array([s['average_vec'] for s in spans])\n",
    "    y = np.array([s['type'] for s in spans])\n",
    "    X = np.concatenate((avg_vec, np.expand_dims(starts_normalized, axis=1), np.expand_dims(num_tokens_normalized, axis=1)), axis=1)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45affbc0-69fc-4793-b7b5-03592f842bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = make_feature_vectors_and_labels(train_spans_new)\n",
    "dev_X, dev_y = make_feature_vectors_and_labels(dev_spans_new)\n",
    "test_X, test_y = make_feature_vectors_and_labels(test_spans_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322d2244-3cca-4fd4-b41b-a4c446c7fc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{train_X.shape} {train_y.shape}')\n",
    "print(f'{dev_X.shape} {dev_y.shape}')\n",
    "print(f'{test_X.shape} {test_y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c043adb4-54fe-4acd-bb5b-c30a86abb0e5",
   "metadata": {},
   "source": [
    "### MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1c3a43-dcdb-4be3-b406-8446257e648e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spans_labels = np.array([s['type'] for s in train_spans_new])\n",
    "dev_spans_labels = np.array([s['type'] for s in dev_spans_new])\n",
    "test_spans_labels = np.array([s['type'] for s in test_spans_new])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6318c59f-e0a3-41ad-8dac-e4f3fba2703d",
   "metadata": {},
   "source": [
    "### Linear Support Vector Machine Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44bfa3d-b18b-4c83-83d8-ab17bf87a8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearSVC(random_state = 0)\n",
    "clf = clf.fit(train_X, train_y)\n",
    "\n",
    "print('TRAIN:\\n'+classification_report(train_spans_labels, clf.predict(train_X)))\n",
    "print('DEV:\\n'+classification_report(dev_spans_labels, clf.predict(dev_X)))\n",
    "\n",
    "plot_confusion_matrix(dev_spans_labels, clf.predict(dev_X), classes=list(clf.classes_),\n",
    "                      title='Confusion matrix for training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23bcd74-416f-4c7a-89c0-bb4aa4ad8a5e",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c8ce6d-b92e-4f4d-899c-bc6af3f24e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state = 0)\n",
    "clf = clf.fit(train_X, train_y)\n",
    "\n",
    "print('TRAIN:\\n'+classification_report(train_spans_labels, clf.predict(train_X)))\n",
    "print('DEV:\\n'+classification_report(dev_spans_labels, clf.predict(dev_X)))\n",
    "\n",
    "plot_confusion_matrix(dev_spans_labels, clf.predict(dev_X), classes=list(clf.classes_),\n",
    "                      title='Confusion matrix for training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d329a5e4-5e79-47ef-b482-9e51303186ff",
   "metadata": {},
   "source": [
    "### Radial kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fff994-5190-43d8-95cf-31d7ed6fc0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter=None, gamma='scale'\n",
    "clf = SVC(kernel = 'rbf', random_state = 0)\n",
    "clf = clf.fit(train_X, train_y)\n",
    "\n",
    "print('TRAIN:\\n'+classification_report(train_spans_labels, clf.predict(train_X)))\n",
    "print('DEV:\\n'+classification_report(dev_spans_labels, clf.predict(dev_X)))\n",
    "\n",
    "plot_confusion_matrix(dev_spans_labels, clf.predict(dev_X), classes=list(clf.classes_),\n",
    "                      title='Confusion matrix for training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7954a526-6caa-468a-9361-85b574529efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter: gamma = 'auto'\n",
    "clf = SVC(kernel = 'rbf', gamma = 'auto', random_state = 0)\n",
    "clf = clf.fit(train_X, train_y)\n",
    "\n",
    "print('TRAIN:\\n'+classification_report(train_spans_labels, clf.predict(train_X)))\n",
    "print('DEV:\\n'+classification_report(dev_spans_labels, clf.predict(dev_X)))\n",
    "\n",
    "plot_confusion_matrix(dev_spans_labels, clf.predict(dev_X), classes=list(clf.classes_),\n",
    "                      title='Confusion matrix for training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f43157a-8e85-4e3d-a3ac-da97a1b97a93",
   "metadata": {},
   "source": [
    "### Polynomial kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2651c5db-0865-41c5-bdfe-8a173f48285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter: None, degree = 3\n",
    "clf = SVC(kernel = 'poly', random_state = 0)\n",
    "clf = clf.fit(train_X, train_y)\n",
    "\n",
    "print('TRAIN:\\n'+classification_report(train_spans_labels, clf.predict(train_X)))\n",
    "print('DEV:\\n'+classification_report(dev_spans_labels, clf.predict(dev_X)))\n",
    "\n",
    "plot_confusion_matrix(dev_spans_labels, clf.predict(dev_X), classes=list(clf.classes_),\n",
    "                      title='Confusion matrix for training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29db214f-a7fd-44db-b6bc-434d3d059ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter: degree = 2\n",
    "clf = SVC(kernel = 'poly', degree = 2, random_state = 0)\n",
    "clf = clf.fit(train_X, train_y)\n",
    "\n",
    "print('TRAIN:\\n'+classification_report(train_spans_labels, clf.predict(train_X)))\n",
    "print('DEV:\\n'+classification_report(dev_spans_labels, clf.predict(dev_X)))\n",
    "\n",
    "plot_confusion_matrix(dev_spans_labels, clf.predict(dev_X), classes=list(clf.classes_),\n",
    "                      title='Confusion matrix for training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1a66ff-bd0e-48d4-9ea3-3d6cf6868813",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9289626d-2619-41e8-a437-398711d49dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter: max_depth = 12\n",
    "clf = tree.DecisionTreeClassifier(max_depth=12)\n",
    "clf = clf.fit(train_X, train_y)\n",
    "\n",
    "print('TRAIN:\\n'+classification_report(train_spans_labels, clf.predict(train_X)))\n",
    "print('DEV:\\n'+classification_report(dev_spans_labels, clf.predict(dev_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42a71e0-6d55-4ad9-921b-405e2e76b87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(dev_spans_labels, clf.predict(dev_X), classes=list(clf.classes_),\n",
    "                      title='Confusion matrix for training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b6cc9f-1a33-4034-b2de-7c733d0b62bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter: max_depth = 22\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_depth=22)\n",
    "clf = clf.fit(train_X, train_y)\n",
    "\n",
    "print('TRAIN:\\n'+classification_report(train_spans_labels, clf.predict(train_X)))\n",
    "print('DEV:\\n'+classification_report(dev_spans_labels, clf.predict(dev_X)))\n",
    "\n",
    "plot_confusion_matrix(dev_spans_labels, clf.predict(dev_X), classes=list(clf.classes_),\n",
    "                      title='Confusion matrix for training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac043a0-efa4-4cbc-bee1-c3b6c39be306",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter: min_samples_split = 10\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(min_samples_split = 10)\n",
    "clf = clf.fit(train_X, train_y)\n",
    "\n",
    "print('TRAIN:\\n'+classification_report(train_spans_labels, clf.predict(train_X)))\n",
    "print('DEV:\\n'+classification_report(dev_spans_labels, clf.predict(dev_X)))\n",
    "\n",
    "plot_confusion_matrix(dev_spans_labels, clf.predict(dev_X), classes=list(clf.classes_),\n",
    "                      title='Confusion matrix for training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af29c344-6127-4d33-861f-6af6c72bc428",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5236f0a5-eca8-45a7-b46d-77348788ac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter: max_depth = 20\n",
    "\n",
    "clf = RandomForestClassifier(max_depth = 20, random_state = 0)\n",
    "clf = clf.fit(train_X, train_y)\n",
    "\n",
    "print('TRAIN:\\n'+classification_report(train_spans_labels, clf.predict(train_X)))\n",
    "print('DEV:\\n'+classification_report(dev_spans_labels, clf.predict(dev_X)))\n",
    "\n",
    "plot_confusion_matrix(dev_spans_labels, clf.predict(dev_X), classes=list(clf.classes_),\n",
    "                      title='Confusion matrix for training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354d1dd6-8d94-4a75-91c9-242c4e79682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter: max_depth = None\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(max_depth = None, random_state = 0)\n",
    "clf = clf.fit(train_X, train_y)\n",
    "\n",
    "print('TRAIN:\\n'+classification_report(train_spans_labels, clf.predict(train_X)))\n",
    "print('DEV:\\n'+classification_report(dev_spans_labels, clf.predict(dev_X)))\n",
    "\n",
    "plot_confusion_matrix(dev_spans_labels, clf.predict(dev_X), classes=list(clf.classes_),\n",
    "                      title='Confusion matrix for training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ef9446-c3a1-451d-ae47-c63fb75b50e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter: n_estimators = 200\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 200, max_depth = 12, random_state = 0)\n",
    "clf = clf.fit(train_X, train_y)\n",
    "\n",
    "print('TRAIN:\\n'+classification_report(train_spans_labels, clf.predict(train_X)))\n",
    "print('DEV:\\n'+classification_report(dev_spans_labels, clf.predict(dev_X)))\n",
    "\n",
    "plot_confusion_matrix(dev_spans_labels, clf.predict(dev_X), classes=list(clf.classes_),\n",
    "                      title='Confusion matrix for training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6affc347-e0ad-4f0b-ac0f-0798eb2a1627",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter: \n",
    "#max_depth = 12\n",
    "\n",
    "clf = RandomForestClassifier(max_depth = 12, random_state = 0)\n",
    "clf = clf.fit(train_X, train_y)\n",
    "\n",
    "print('TRAIN:\\n'+classification_report(train_spans_labels, clf.predict(train_X)))\n",
    "print('DEV:\\n'+classification_report(dev_spans_labels, clf.predict(dev_X)))\n",
    "\n",
    "plot_confusion_matrix(dev_spans_labels, clf.predict(dev_X), classes=list(clf.classes_),\n",
    "                      title='Confusion matrix for training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e9ea5d-0dd1-44f2-b4c2-3f43228ce00a",
   "metadata": {},
   "source": [
    "## Best Model Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06812e65-0a53-4215-ac72-78e03876cd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter=None, gamma='scale'\n",
    "clf = SVC(kernel = 'rbf', random_state = 0)\n",
    "clf = clf.fit(train_X, train_y)\n",
    "\n",
    "print('TRAIN:\\n'+classification_report(train_spans_labels, clf.predict(train_X)))\n",
    "print('DEV:\\n'+classification_report(dev_spans_labels, clf.predict(dev_X)))\n",
    "\n",
    "plot_confusion_matrix(dev_spans_labels, clf.predict(dev_X), classes=list(clf.classes_),\n",
    "                      title='Confusion matrix for DEV data for \\n Radial SVM')\n",
    "plt.show()\n",
    "\n",
    "print('TEST:\\n'+classification_report(test_spans_labels, clf.predict(test_X)))\n",
    "plot_confusion_matrix(test_spans_labels, clf.predict(test_X), classes=list(clf.classes_),\n",
    "                      title='Confusion matrix for TEST data for \\n Radial SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e12e43-7c37-4085-9861-687026e34b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE MODEL\n",
    "joblib.dump(clf, 'RSVM_best_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9fc47e-7713-4b38-a4de-3a6cd1ef78f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD MODEL\n",
    "clf = load('RSVM_best_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3046ae10-e5dd-489a-9112-ace7c8a28048",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d5c39b-dab8-4852-aedd-acbe4da7f930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_errors(clf, eval_spans, \n",
    "                      select_true_label=None, \n",
    "                      select_pred_label=None):\n",
    "    eval_X, eval_y = make_feature_vectors_and_labels(eval_spans)\n",
    "    eval_spans_txt = [s['txt'] for s in eval_spans]\n",
    "    eval_spans_labels = [s['type'] for s in eval_spans]\n",
    "    pred_y = clf.predict(eval_X)\n",
    "    for i in range(len(eval_spans)):\n",
    "        true_label = eval_spans_labels[i]\n",
    "        pred_label = pred_y[i]\n",
    "        if true_label != pred_label:\n",
    "            if select_true_label and true_label != select_true_label: continue\n",
    "            if select_pred_label and pred_label != select_pred_label: continue\n",
    "            doc_name = documents_by_id[eval_spans[i]['document']]['name']\n",
    "            print('sentence # '+str(i)+' / case '+doc_name+' / @'+str(eval_spans[i]['start']))\n",
    "            print('pred: '+pred_label+' / true: '+true_label)\n",
    "            print(eval_spans[i]['txt'])\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bc51bd-61c0-45e6-8a20-1b4e6a50eb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_errors(clf,\n",
    "                  random.sample(train_spans_new, 500),\n",
    "                  select_pred_label='EvidenceBased/Intermediate Finding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae40322-9d71-46be-818a-fcdacd8f78c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_errors(clf,\n",
    "                  random.sample(train_spans_new, 500),\n",
    "                  select_pred_label='EvidenceBasedReasoning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8736a4-019c-4929-a8ef-c9f8016660dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_errors(clf,\n",
    "                  random.sample(train_spans_new, 500),\n",
    "                  select_pred_label='ConclusionOfLaw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149e3ffd-dd28-4bd1-9906-41b3b176fe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_errors(clf,\n",
    "                  random.sample(train_spans_new, 500),\n",
    "                  select_true_label='ConclusionOfLaw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caab9188-55f0-4b0a-84ce-50d39b44ba4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_errors(clf,\n",
    "                  random.sample(train_spans_new, 500),\n",
    "                  select_pred_label='RemandInstructions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5b0bac-86c1-4916-b06b-b7cec29728e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_errors(clf,\n",
    "                  random.sample(train_spans_new, 500),\n",
    "                  select_true_label='RemandInstructions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8c6064-496b-4003-a788-7863180484f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_errors(clf,\n",
    "                  random.sample(train_spans_new, 500),\n",
    "                  select_pred_label='LegalPolicy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce1691c-ba43-43c4-81dd-7aff86c4dd8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
